{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits classification with MLPs\n",
    "\n",
    "Copyright 2018 Google LLC.<br/>\n",
    "Copyright 2021 CSC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "---------\n",
    "\n",
    "In this notebook, we'll train a multi-layer perceptron model to classify MNIST digits using pure **Jax**. \n",
    "\n",
    "This notebook is partly copied and adapted from https://github.com/google/jax/blob/master/docs/notebooks/Neural_Network_and_Data_Loading.ipynb\n",
    "\n",
    "First, the needed imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random, __version__\n",
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "device = xla_bridge.get_backend().platform\n",
    "\n",
    "print('Using Jax version:', __version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Next we'll load the MNIST data.  We are using Pytorch's `torchvision` for this purpose. First time we may have to download the data, which can take a while.\n",
    "\n",
    "Note that we are here using the MNIST test data for *validation*, instead of for testing the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_targets = 10\n",
    "\n",
    "train_dataset = datasets.MNIST('../MNIST', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "validation_dataset = datasets.MNIST('../MNIST', \n",
    "                                    train=False, \n",
    "                                    transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
    "                                                batch_size=batch_size, \n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test data are provided via data loaders that provide iterators over the datasets. The first element of training data (`X_train`) is a 4th-order tensor of size (`batch_size`, 1, 28, 28), i.e. it consists of a batch of images of size 1x28x28 pixels. `y_train` is a vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first 10 training digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltsize=1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray_r\")\n",
    "    plt.title('Class: '+str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP network definition\n",
    "\n",
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [784, 512, 512, 10]\n",
    "step_size = 0.01\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "def random_layer_params(m, n, key, scale=1e-2):\n",
    "  w_key, b_key = random.split(key)\n",
    "  return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "\n",
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key):\n",
    "  keys = random.split(key, len(sizes))\n",
    "  return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "\n",
    "params = init_network_params(layer_sizes, random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7APc6tD7TiuZ"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "  return jnp.maximum(0, x)\n",
    "\n",
    "def predict(params, image):\n",
    "  # per-example predictions\n",
    "  activations = image\n",
    "  for w, b in params[:-1]:\n",
    "    outputs = jnp.dot(w, activations) + b\n",
    "    activations = relu(outputs)\n",
    "  \n",
    "  final_w, final_b = params[-1]\n",
    "  logits = jnp.dot(final_w, activations) + final_b\n",
    "  return logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass for a single image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sW2A5mnXHc5",
    "outputId": "9d3b29e8-fab3-4ecb-9f63-bc8c092f9006"
   },
   "outputs": [],
   "source": [
    "random_flattened_image = random.normal(random.PRNGKey(1), (28 * 28,))\n",
    "preds = predict(params, random_flattened_image)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pass for a batch of images, using `vmap()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJOOncKMXbwK",
    "outputId": "31285fab-7667-4871-fcba-28e86adc3fc6"
   },
   "outputs": [],
   "source": [
    "random_flattened_images = random.normal(random.PRNGKey(1), (10, 28 * 28))\n",
    "\n",
    "# Make a batched version of the `predict` function\n",
    "batched_predict = vmap(predict, in_axes=(None, 0))\n",
    "\n",
    "# `batched_predict` has the same call signature as `predict`\n",
    "batched_preds = batched_predict(params, random_flattened_images)\n",
    "print(batched_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lTI6I4lWdh5"
   },
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "  return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "  \n",
    "def accuracy(params, images, targets):\n",
    "  target_class = jnp.argmax(targets, axis=1)\n",
    "  predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
    "  return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "def loss(params, images, targets):\n",
    "  preds = batched_predict(params, images)\n",
    "  return -jnp.mean(preds * targets)\n",
    "\n",
    "@jit\n",
    "def update(params, x, y):\n",
    "  grads = grad(loss)(params, x, y)\n",
    "  return [(w - step_size * dw, b - step_size * db)\n",
    "          for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = jnp.array(train_dataset.data.numpy()\n",
    "                        .reshape(len(train_dataset.data),-1), \n",
    "                        dtype=jnp.float32)\n",
    "train_labels = one_hot(jnp.array(train_dataset.targets), n_targets)\n",
    "\n",
    "validation_images = jnp.array(validation_dataset.data.numpy()\n",
    "                              .reshape(len(validation_dataset.data),-1), \n",
    "                              dtype=jnp.float32)\n",
    "validation_labels = one_hot(jnp.array(validation_dataset.targets), n_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train our model.  An *epoch* means one pass through the whole training data. After each epoch, we evaluate the model by computing accuracy and loss values for training and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2DnZo3iYj18",
    "outputId": "0eba3ca2-24a1-4cba-aaf4-3ac61d0c650e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = np.zeros((num_epochs, 4))\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for x, y in train_loader:\n",
    "        y = one_hot(jnp.array(y), n_targets)\n",
    "        x = jnp.array(x).reshape(batch_size, -1)\n",
    "        params = update(params, x, y)\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    train_acc = accuracy(params, train_images, train_labels)\n",
    "    train_loss = loss(params, train_images, train_labels)\n",
    "    validation_acc = accuracy(params, validation_images, validation_labels)\n",
    "    validation_loss = loss(params, validation_images, validation_labels)\n",
    "    history[epoch,:] = [np.asarray(x) for x in [train_acc, train_loss, \n",
    "                                                validation_acc, validation_loss]]\n",
    "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "    print(\"Training set accuracy:   \"\n",
    "          \"{:0.4f}, loss: {:0.4f}\".format(train_acc, train_loss))\n",
    "    print(\"Validation set accuracy: \"\n",
    "          \"{:0.4f}, loss: {:0.4f}\".format(validation_acc, validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize how the training progressed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(range(num_epochs), history[:,0], label='training')\n",
    "plt.plot(range(num_epochs), history[:,2], label='validation')\n",
    "plt.title('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(range(num_epochs), history[:,1], label='training')\n",
    "plt.plot(range(num_epochs), history[:,3], label='validation')\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
